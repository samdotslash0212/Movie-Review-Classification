{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPE2CmTrHruqKTv1PRp+57g"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYWB-_mhqK31"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import itertools\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import optimizers, Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "lEzfGWdxtwOK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c68746b5-4511-4829-a98f-146b39fd095c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **LSTM**"
      ],
      "metadata": {
        "id": "OfGiipVks42D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "names = ['index','review', 'sentiment', 'label']\n",
        "df = pd.read_csv('/content/drive/MyDrive/imdb/train_data.csv', sep=',', names=names, header=0)\n",
        "#df_val = pd.read_csv('val.csv', sep=',', names=names, header=0)\n",
        "#df=pd.concat((df_train, df_val))\n",
        "df.dropna(how='any', inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "df[\"review\"] = df['review'].values.astype('U')\n",
        "X = df['review'].to_numpy()\n",
        "Y = df['label'].to_numpy()\n",
        "print(X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVcYjcgvFiHY",
        "outputId": "a31a26c5-2df7-4827-8119-7ac4a4298453"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_tr, X_val, Y_tr, Y_val = train_test_split(X, Y, test_size=0.25, random_state=0)"
      ],
      "metadata": {
        "id": "dfsftW7WF6TV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_FEATURES = 10000\n",
        "tfidf = TfidfVectorizer(max_features = MAX_FEATURES)\n",
        "tfidf.fit(X_tr)\n",
        "X_train = tfidf.transform(X_tr)\n",
        "X_train = X_train.todense()\n",
        "X_tr=X_train\n",
        "\n",
        "\n",
        "X_val=tfidf.transform(X_val)\n",
        "X_val=X_val.todense()"
      ],
      "metadata": {
        "id": "43Wuf68hGMhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_tr=np.array(X_tr)\n",
        "Y_tr=np.array(Y_tr)"
      ],
      "metadata": {
        "id": "v5qhPIzlGPqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_Iso = IsolationForest(random_state=np.random.RandomState(0),n_jobs = -1)\n",
        "clf_Iso.fit(X_tr)\n",
        "Y_Iso_Forest = clf_Iso.predict(X_tr)\n",
        "result = np.where(Y_Iso_Forest == -1)\n",
        "result = list(itertools.chain.from_iterable(result))"
      ],
      "metadata": {
        "id": "UCYKl_SfGSxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_removed = np.delete(X_tr,result,axis = 0)\n",
        "if Y_tr is None:\n",
        "    X_train=X_removed\n",
        "else:\n",
        "    Y_removed = np.delete(Y_tr,result,axis = 0)\n",
        "X_tr=X_removed\n",
        "Y_tr=Y_removed"
      ],
      "metadata": {
        "id": "yHF3Lf1aGWLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "look_back=1\n",
        "num_samples=X_tr.shape[0]\n",
        "num_features=X_tr.shape[1]\n",
        "X_tr= np.reshape(np.array(X_tr), (num_samples, look_back, num_features))"
      ],
      "metadata": {
        "id": "DnZXT3RmG_UL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=128"
      ],
      "metadata": {
        "id": "1ZPTqCGKGsfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(look_back=None, input_nodes=None, activation='relu', \n",
        "                optimizer='adam', hidden_layers=2, neurons=400, hidden_units=600):\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.LSTM(hidden_units, dropout=0.2, \n",
        "                                input_shape=(look_back, input_nodes)))\n",
        "    \n",
        "    for _ in range(hidden_layers):\n",
        "        model.add(keras.layers.Dense(neurons, activation=activation))\n",
        "\n",
        "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer, \n",
        "                    metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "Ca8LPOr3GsMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5 # can change this\n",
        "kf = KFold(n_splits=3, random_state=None)\n",
        "acc_list = []\n",
        "X_train = None # init\n",
        "X_test = None # init\n",
        "Y_test = None #init\n",
        "# Doing cross validation testing\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X_tr[train_index], X_tr[test_index]\n",
        "    Y_train, Y_test = Y_tr[train_index], Y_tr[test_index]\n",
        "    model = create_model(look_back=look_back, input_nodes=num_features)\n",
        "    history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=epochs, batch_size=batch_size)\n",
        "    print(\"----Start Evaluating----\")\n",
        "    _, acc = model.evaluate(X_test, Y_test, verbose=1)\n",
        "    acc_list.append(acc)\n",
        "    print(\"Testing Accuracy:\", acc)\n",
        "print(\"Mean testing accuracy:\", sum(acc_list) / len(acc_list)"
      ],
      "metadata": {
        "id": "b6e-Q4dNGZtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_,acc_val = model.evaluate(X_val, Y_val, verbose=1)\n",
        "print('Validation accuracy:', acc_val)"
      ],
      "metadata": {
        "id": "N5UB6J3QHP9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_probs = model.predict(X_val).reshape(X_val.shape[0])\n",
        "\n",
        "np.savetxt('lstm_probs.csv', lstm_probs, delimiter=',', header='probs')"
      ],
      "metadata": {
        "id": "d5jgpus-Hjih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_preds = (lstm_probs >= 0.5).astype(\"int32\")\n",
        "np.savetxt('lstm_preds.csv', lstm_preds, delimiter=',', header='preds')"
      ],
      "metadata": {
        "id": "HBz-7aZFHrRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_cm = confusion_matrix(np.array(y_val), lstm_preds)\n",
        "print(lstm_cm) "
      ],
      "metadata": {
        "id": "tqKn7AmoHu2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save best model\n",
        "lstm_best = lstm_gs.best_estimator_\n",
        "#check best n_estimators value\n",
        "print(lstm_gs.best_params_)"
      ],
      "metadata": {
        "id": "H62ucTJYTwx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **SVM**"
      ],
      "metadata": {
        "id": "zlO4zO5PtREZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "names = ['index','review', 'sentiment', 'label']\n",
        "df = pd.read_csv('/content/drive/MyDrive/imdb/train_data.csv', sep=',', names=names, header=0)\n",
        "#df_val = pd.read_csv('val.csv', sep=',', names=names, header=0)\n",
        "#df=pd.concat((df_train, df_val))\n",
        "df.dropna(how='any', inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "df[\"review\"] = df['review'].values.astype('U')\n",
        "X = df['review'].to_numpy()\n",
        "Y = df['label'].to_numpy()\n",
        "print(X.shape)"
      ],
      "metadata": {
        "id": "tQKj3dZXqV0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_tr, X_val, Y_tr, Y_val = train_test_split(X, Y, test_size=0.25, random_state=0)"
      ],
      "metadata": {
        "id": "57WI1fI0t0a4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_FEATURES = 10000\n",
        "tfidf = TfidfVectorizer(max_features = MAX_FEATURES)\n",
        "tfidf.fit(X_tr)\n",
        "X_train = tfidf.transform(X_tr)\n",
        "X_train = X_train.todense()\n",
        "X_tr=X_train\n",
        "\n",
        "\n",
        "X_val=tfidf.transform(X_val)\n",
        "X_val=X_val.todense()"
      ],
      "metadata": {
        "id": "jbDmXdngt-2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_tr=np.array(X_tr)\n",
        "Y_tr=np.array(Y_tr)"
      ],
      "metadata": {
        "id": "DMwEMrKDuAQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_Iso = IsolationForest(random_state=np.random.RandomState(0),n_jobs = -1)\n",
        "clf_Iso.fit(X_tr)\n",
        "Y_Iso_Forest = clf_Iso.predict(X_tr)\n",
        "result = np.where(Y_Iso_Forest == -1)\n",
        "result = list(itertools.chain.from_iterable(result))"
      ],
      "metadata": {
        "id": "KN5Oh5kuuJfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_removed = np.delete(X_tr,result,axis = 0)\n",
        "if Y_tr is None:\n",
        "    X_train=X_removed\n",
        "else:\n",
        "    Y_removed = np.delete(Y_tr,result,axis = 0)\n",
        "X_tr=X_removed\n",
        "Y_tr=Y_removed"
      ],
      "metadata": {
        "id": "iulFLfcGuKbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kf = KFold(n_splits=10)\n",
        "svm = SVC(C=1, kernel='rbf')\n",
        "acc_list = []\n",
        "for train_index, test_index in kf.split(X_tr):\n",
        "    X_train, X_test = X_tr[train_index], X_tr[test_index]\n",
        "    Y_train, Y_test = Y_tr[train_index], Y_tr[test_index]\n",
        "    svm.fit(X_train, Y_train)\n",
        "    print(\"----Start Evaluating----\")\n",
        "    acc = svm.score(X_test, Y_test)\n",
        "    acc_list.append(acc)\n",
        "    print(\"Testing Accuracy:\", acc)\n",
        "print(\"Mean testing accuracy:\", sum(acc_list) / len(acc_list))"
      ],
      "metadata": {
        "id": "-B0OpdGMuVLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_val = svm.score(X_val, Y_val)\n",
        "print('Validation accuracy:', acc_val)"
      ],
      "metadata": {
        "id": "nuwnDBTfuZGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm_probs = svm.predict_proba(X_val)[:, 1]\n",
        "np.savetxt('svm_probs.csv', svm_probs, delimiter=',', header='probs')\n",
        "svm_preds = svm.predict(X_val)\n",
        "np.savetxt('svm_preds.csv', svm_preds, delimiter=',', header='preds')"
      ],
      "metadata": {
        "id": "-pdqV7BAunUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm_cm = confusion_matrix(np.array(Y_val), svm_preds)\n",
        "print(svm_cm)"
      ],
      "metadata": {
        "id": "KsRTYXOhuoSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **LOGREG**"
      ],
      "metadata": {
        "id": "CQV6kCmjvEao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "names = ['index','review', 'sentiment', 'label']\n",
        "df = pd.read_csv('/content/drive/MyDrive/imdb/train_data.csv', sep=',', names=names, header=0)\n",
        "#df_val = pd.read_csv('val.csv', sep=',', names=names, header=0)\n",
        "#df=pd.concat((df_train, df_val))\n",
        "df.dropna(how='any', inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "df[\"review\"] = df['review'].values.astype('U')\n",
        "X = df['review'].to_numpy()\n",
        "Y = df['label'].to_numpy()\n",
        "print(X.shape)"
      ],
      "metadata": {
        "id": "LwbslvXNvDnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_tr, X_val, Y_tr, Y_val = train_test_split(X, Y, test_size=0.25, random_state=0)"
      ],
      "metadata": {
        "id": "v3ATnd3wvSbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_FEATURES = 10000\n",
        "cv = CountVectorizer(max_features = MAX_FEATURES)\n",
        "cv.fit(X_tr)\n",
        "X_train = cv.transform(X_tr)\n",
        "X_train = X_train.todense()\n",
        "X_tr=X_train\n",
        "\n",
        "\n",
        "X_valid=cv.transform(X_val)\n",
        "X_valid=X_valid.todense()\n",
        "X_val=X_valid\n"
      ],
      "metadata": {
        "id": "mSym5-IfvbhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_tr=np.array(X_tr)\n",
        "Y_tr=np.array(Y_tr)"
      ],
      "metadata": {
        "id": "3aR75yVtvdbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_Iso = IsolationForest(random_state=np.random.RandomState(0),n_jobs = -1)\n",
        "clf_Iso.fit(X_tr)\n",
        "Y_Iso_Forest = clf_Iso.predict(X_tr)\n",
        "result = np.where(Y_Iso_Forest == -1)\n",
        "result = list(itertools.chain.from_iterable(result))"
      ],
      "metadata": {
        "id": "H9n5mC5-wJLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_removed = np.delete(X_tr,result,axis = 0)\n",
        "if Y_tr is None:\n",
        "    X_train=X_removed\n",
        "else:\n",
        "    Y_removed = np.delete(Y_tr,result,axis = 0)\n",
        "X_tr=X_removed\n",
        "Y_tr=Y_removed"
      ],
      "metadata": {
        "id": "kG_MWBaGwKB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_tr.shape, Y_tr.shape)"
      ],
      "metadata": {
        "id": "MMICdwltwNGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = X_tr.shape[0]\n",
        "num_features = X_tr.shape[1]\n",
        "X_tr = np.reshape(np.array(X_tr), (num_samples, num_features))"
      ],
      "metadata": {
        "id": "KpVZy_LNwPee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "C = 1 \n",
        "solver = 'sag' \n",
        "kf = KFold(n_splits=5)\n",
        "logistic = LogisticRegression(max_iter=500, C=C, solver=solver)\n",
        "acc_list = []\n",
        "# Doing cross validation testing\n",
        "for train_index, test_index in kf.split(X_tr):\n",
        "    X_train, X_test = X_tr[train_index], X_tr[test_index]\n",
        "    Y_train, Y_test = Y_tr[train_index], Y_tr[test_index]\n",
        "    logistic.fit(X_train, Y_train)\n",
        "    print(\"----Start Evaluating----\")\n",
        "    acc = logistic.score(X_test, Y_test)\n",
        "    acc_list.append(acc)\n",
        "    print(\"Testing Accuracy:\", acc)\n",
        "print(\"Mean testing accuracy:\", sum(acc_list) / len(acc_list))"
      ],
      "metadata": {
        "id": "IBpxDVNcwSlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_val = logistic.score(X_val, Y_val)\n",
        "print('Validation accuracy:', acc_val)"
      ],
      "metadata": {
        "id": "H-EVO-qKwWe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logreg_probs = logistic.predict_proba(X_val)[:, 1]\n",
        "np.savetxt('logreg_probs.csv', logreg_probs, delimiter=',', header='probs')\n",
        "logreg_preds = logistic.predict(X_val)\n",
        "np.savetxt('logreg_preds.csv', logreg_preds, delimiter=',', header='preds')"
      ],
      "metadata": {
        "id": "CaAV7I0gwgOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_cm = confusion_matrix(np.array(Y_val), logreg_preds)\n",
        "print(lr_cm)"
      ],
      "metadata": {
        "id": "r-PaZLOJwhZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "VOTING CLASSIFIER"
      ],
      "metadata": {
        "id": "hBG2hphBVFml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "#create a dictionary of our models\n",
        "estimators=[(‘lstm’, model), (‘svm’, svm), (‘logistic’, logistic)]\n",
        "#create our voting classifier, inputting our models\n",
        "ensemble = VotingClassifier(estimators, voting=’hard’)"
      ],
      "metadata": {
        "id": "mzLjI2xzLtza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fit model to training data\n",
        "ensemble.fit(X_tr, Y_tr)\n",
        "#test our model on the test data\n",
        "ensemble.score(X, Y)"
      ],
      "metadata": {
        "id": "m8z63suyVmBu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}